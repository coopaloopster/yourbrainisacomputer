{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Feed Forward Multilayer Percepton Artificial Neural Network for Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [3, 5, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize sample data vectors and classify them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialValues = [[0.74,0.1354,0.87]]\n",
    "initialValQuad = [[1,0]]\n",
    "num = 0\n",
    "dataSize = 100\n",
    "index = 5\n",
    "while (num < dataSize):\n",
    "    num += 1\n",
    "    ran = 1 - (2 * np.random.rand(1,3))\n",
    "    initialValues = np.concatenate((initialValues,ran))\n",
    "    if ran[0][2] > 0:\n",
    "        initialValQuad = np.concatenate((initialValQuad,[[1,0]]), axis=0)\n",
    "    else:\n",
    "        initialValQuad = np.concatenate((initialValQuad,[[0,1]]), axis=0)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line below isn't really necessary anymore but I'm leaving it just cause, feel free to remove it or anything else\n",
    "# input1 = 1-2*np.random.rand(1,network[0])\n",
    "w1 = 1-2*np.random.rand(network[0],network[1])\n",
    "w2 = 1-2*np.random.rand(network[1],network[2])\n",
    "b1 = 1-2*np.random.rand(1,network[1])\n",
    "b2 = 1-2*np.random.rand(1,network[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sigmoid Activation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function for now, once we get past function and into optimization, we could use try others like TanH, ArcTan, or even ReLU\n",
    "def activate(inputs,weights,biases):\n",
    "   info = np.dot(inputs,weights)-biases\n",
    "   return 1 / (1 + np.exp(-info))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52458017 0.49482855]]\n",
      "[[0.49865162 0.57069068]]\n",
      "[[0.51569723 0.5575522 ]]\n",
      "[[0.54993917 0.48490634]]\n",
      "[[0.52435081 0.5073498 ]]\n",
      "[[0.54532286 0.51482978]]\n",
      "[[0.52241397 0.51419998]]\n",
      "[[0.53934772 0.48057259]]\n",
      "[[0.51831744 0.53424858]]\n",
      "[[0.52405391 0.53028298]]\n",
      "[[0.45394811 0.61364326]]\n",
      "[[0.51252318 0.50786119]]\n",
      "[[0.54777662 0.47430914]]\n",
      "[[0.51640935 0.53400138]]\n",
      "[[0.46653109 0.57485735]]\n",
      "[[0.45781987 0.56143643]]\n",
      "[[0.5065669  0.55627689]]\n",
      "[[0.46242295 0.57064203]]\n",
      "[[0.55422626 0.48865422]]\n",
      "[[0.49306958 0.56531183]]\n",
      "[[0.52209408 0.52709793]]\n",
      "[[0.55515554 0.46477212]]\n",
      "[[0.45901275 0.55427167]]\n",
      "[[0.55764356 0.50279304]]\n",
      "[[0.5427707 0.4892702]]\n",
      "[[0.46107923 0.55064317]]\n",
      "[[0.53131876 0.50578547]]\n",
      "[[0.46508748 0.58877862]]\n",
      "[[0.5200211  0.50194613]]\n",
      "[[0.57683232 0.46246328]]\n",
      "[[0.49453047 0.56031634]]\n",
      "[[0.54421645 0.49339969]]\n",
      "[[0.47295971 0.59214332]]\n",
      "[[0.52344303 0.4919732 ]]\n",
      "[[0.46198904 0.6006042 ]]\n",
      "[[0.46686244 0.59036747]]\n",
      "[[0.49267013 0.57769096]]\n",
      "[[0.45480595 0.60654665]]\n",
      "[[0.50707548 0.54508084]]\n",
      "[[0.55011233 0.489325  ]]\n",
      "[[0.53803384 0.49049465]]\n",
      "[[0.50057977 0.51591285]]\n",
      "[[0.54794582 0.4970331 ]]\n",
      "[[0.54333794 0.49626731]]\n",
      "[[0.54720775 0.51266455]]\n",
      "[[0.55438507 0.50700914]]\n",
      "[[0.49952743 0.51547351]]\n",
      "[[0.46570218 0.59754899]]\n",
      "[[0.52306968 0.54185847]]\n",
      "[[0.56146418 0.49968112]]\n",
      "[[0.52543692 0.53983615]]\n",
      "[[0.48518142 0.52644096]]\n",
      "[[0.4610012  0.59445315]]\n",
      "[[0.45665126 0.56303   ]]\n",
      "[[0.55103245 0.4776301 ]]\n",
      "[[0.53628204 0.52431382]]\n",
      "[[0.50529933 0.526792  ]]\n",
      "[[0.57161765 0.47799021]]\n",
      "[[0.47348312 0.5721757 ]]\n",
      "[[0.52816121 0.50496787]]\n",
      "[[0.54131807 0.47891913]]\n",
      "[[0.51245569 0.56578789]]\n",
      "[[0.56847095 0.46434935]]\n",
      "[[0.54661209 0.48203817]]\n",
      "[[0.49917763 0.52011435]]\n",
      "[[0.47357191 0.58599929]]\n",
      "[[0.54647296 0.52088674]]\n",
      "[[0.48370741 0.523832  ]]\n",
      "[[0.4848537  0.57671536]]\n",
      "[[0.46625236 0.5531498 ]]\n",
      "[[0.49939983 0.535863  ]]\n",
      "[[0.51399296 0.54276182]]\n",
      "[[0.47815027 0.53871486]]\n",
      "[[0.56735997 0.49820245]]\n",
      "[[0.55565121 0.50347734]]\n",
      "[[0.48238961 0.57752238]]\n",
      "[[0.55842323 0.5050589 ]]\n",
      "[[0.53456522 0.49479315]]\n",
      "[[0.52099862 0.51445539]]\n",
      "[[0.55551384 0.49991882]]\n",
      "[[0.47696511 0.54299302]]\n",
      "[[0.47976341 0.52740282]]\n",
      "[[0.47926278 0.56667497]]\n",
      "[[0.50423721 0.54416943]]\n",
      "[[0.54408871 0.51587121]]\n",
      "[[0.49567706 0.56699112]]\n",
      "[[0.50051212 0.52706575]]\n",
      "[[0.53860236 0.49184381]]\n",
      "[[0.50327219 0.52127341]]\n",
      "[[0.48941208 0.52673884]]\n",
      "[[0.47903807 0.54040528]]\n",
      "[[0.54914686 0.51668508]]\n",
      "[[0.47656513 0.5535622 ]]\n",
      "[[0.49358954 0.51658269]]\n",
      "[[0.54404381 0.49383156]]\n",
      "[[0.5767553 0.4521265]]\n",
      "[[0.47717616 0.54637397]]\n",
      "[[0.50728248 0.56447527]]\n",
      "[[0.51869198 0.52818395]]\n",
      "[[0.54399333 0.51535158]]\n"
     ]
    }
   ],
   "source": [
    "# We could change this to a while/for loop to make it customizable to the number of layers we have in our network\n",
    "# the parameter could be the length(network)\\\n",
    "i = 0\n",
    "while (i < dataSize):\n",
    "    i+= 1\n",
    "    networkGuess = activate(activate(initialValues[i],w1,b1),w2,b2)\n",
    "    print(networkGuess)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
